略称,Year,Paper URL,Website URL,Challenge Tag,Sub-Challeng Tag,How to Solve,Training Type,Dataset,Evaluation
OTTER,2021,https://arxiv.org/pdf/2503.03734?,https://ottervla.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Introdues a text-aware feature extraction which preserves semantics aligned with task descriptions,BC,OXE; DS-PnP;DS-ALL,LIBERO;Real-Robot Evaluation
LIV,2023,https://proceedings.mlr.press/v202/ma23b/ma23b.pdf,https://penn-pal-lab.github.io/LIV/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Introdues a contrastive framework on robot-control data to construct a joint vision-language embedding space,RL,EPIC-KITCHENS-100;MetaWorld;FrankaKitchen;Self-built Data,FrankaKitchen;Self-built Data;MetaWorld;FrankaKitchen
ACT-LLM,2025,https://arxiv.org/pdf/2506.21250,https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Formulates raw per- ceptual inputs into structured language representation,RL,CLIPORT,CLIPORT;VIMA-BENCH
Look-Leap,2023,https://arxiv.org/pdf/2311.17842,robot-vila.github.io,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Structured action-plan generation from visual inputs,Predictive Modeling,Self-built Data,CLIPORT;Self-built Data
RT-2,2023,https://arxiv.org/abs/2307.15818,https://robotics-transformer.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Fine-tuning a pretrained VLM to directly output action tokens,BC,WebLI;Language-Table,Seen Tasks;Self-built Data
Prompt-a-Robot-to-Walk,2023,https://arxiv.org/abs/2309.09969,https://prompt2walk.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Fine-tuning a pretrained VLM to directly output action tokens,BC; Predictive Modeling,None,MuJoCo;Isaac Gym
Grounding MLLMs,2024,https://arxiv.org/pdf/2406.07904,https://github.com/mbzuai-oryx/groundingLMM,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Fine-tuning a pretrained VLM to directly output action tokens,BC,CALVIN;Meta-World;Habitat Pick,CALVIN;Meta-World;Habitat Pick
OpenVLA,2024,https://arxiv.org/pdf/2406.09246,https://openvla.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Fine-tuning a pretrained VLM to directly output action tokens,BC,OXE,BridgeData V2;Google Robot
CLIP-RT,2024,https://arxiv.org/pdf/2411.00508,https://clip-rt.github.io,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Extends CLIP-style vision-language alignment,BC,OXE,LIBERO
Humanoid-VLA,2025,https://arxiv.org/pdf/2502.14795,https://github.com/AllenXuuu/HumanVLA,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Pre-training language-action,BC; Predictive Modeling; RL,Motion Capture;Online Videos;Synthetic Data,IsaacGym;T2M
VoxPoser,2023,https://arxiv.org/pdf/2307.05973,https://voxposer.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Generate intermediate programs and 3D affordance maps as strong intermediate representations by LLM,BC,Online Experiences,RLBench
Orion,2025,https://arxiv.org/pdf/2503.19755,https://xiaomi-mlab.github.io/Orion/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Introduces a high-level VLM planner with a separate low-level motion controller,BC,Bench2Drive base set; Chat-B2D Dataset;,nuScenes;Bench2Drive
Gemini RObotics,2025,https://arxiv.org/pdf/2503.20020,https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Introduces a high-level VLM planner with a separate low-level motion controller,BC and Predictive Modeling,Self-built Data,Manipulation Tasks
KnowledgeVLA,2025,https://arxiv.org/abs/2505.23705,https://www.pi.website/research/knowledge_insulation,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Introduces a high-level VLM planner with a separate low-level motion controller,BC,OXE,LIBERO;DROID
Beyond Sight,2025,https://arxiv.org/pdf/2501.04693,https://fuse-model.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Incorporating additional modalities,BC ,OXE,Self-built Data;Octo
RH-20T,2023,https://arxiv.org/pdf/2307.00595,https://rh20t.github.io./,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Incorporating additional modalities,BC , RH20T, RH20T
TouchVLA,2025,https://arxiv.org/pdf/2507.17294,https://clear-nus.github.io/blog/vla-touch,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Incorporating additional modalities,BC ,Self-built Data,Self-built Data
TLA,2025,https://arxiv.org/pdf/2503.08548,https://sites.google.com/view/tactile-language-action/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Introduces tactile perception,BC,TLA,Custom Contact-Rich Manipulation Benchmark
OmniVTLA,2025,https://arxiv.org/pdf/2508.08706,https://github.com/linchangyi1/Awesome-Touch,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Constructs a se mantically aligned tactile encoder ,BC ,Self-built Data,Real-Robot Evaluation
Tactile-VLA,2025,https://arxiv.org/pdf/2507.09160,https://jialeihuang.github.io/tactileVLA.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Ranging from deep fusion across the full pipeline,BC ,Self-built Data,Real-Robot Evaluation
ForceVLA,2025,https://arxiv.org/pdf/2505.22159,https://sites.google.com/view/forcevla2025/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Modular mixture-of-experts (MoE) fusion ,BC ,Force-VLA-Dataset,Force-VLA-Benchmark
MultiGen,2025,https://arxiv.org/html/2507.02864v2,https://multigen-audio.github.io/,Multi-Modal Fusion and Physical World Representation     ,The GAP between Sematics Perception and Physical Interation,Uses multimodal generation for simulated multi-modal data,BC ,Self-built Data;EPIC-Kitchens,Real-Robot Evaluation
Depth Helps,2024,https://arxiv.org/pdf/2408.05107,https://gewu-lab.github.io/DepthHelps-IROS2024/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Treats depth as a supervisory signal,BC,LIBERO;Self-built Data,LIBERO
RoboFlamingo-Plus,2025,https://arxiv.org/pdf/2503.19510,-,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Fuses preprocessed depth maps  with RGB features,BC ,CALVIN,CALVIN
PointVLA,2025,https://arxiv.org/pdf/2503.07511,https://pointvla.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,integrates point cloud inputs into pretrained VLA models to improve spatial reasoning without modifying the backbone,BC,Self-built Data,Self-built Data
Leo,2023,https://arxiv.org/pdf/2311.12871,https://embodied-generalist.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,unify 2D and 3D modalities,BC,LEO,CLIPort;AI Habitat ObjNav
GeoVLA,2025,https://arxiv.org/pdf/2508.09071,https://linsun449.github.io/GeoVLA,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,unify 2D and 3D modalities,BC,OXE,LIBERO;ManiSkill2
FP3,2025,https://arxiv.org/pdf/2503.08950,https://3d-foundation-policy.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Uses a point-cloud–centric pipeline reconstruction,BC ,DROID;Self-built Data,-
SoFar,2025,https://arxiv.org/pdf/2502.13143,https://qizekun.github.io/sofar/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Constructs semantic 3D scene graphs by integrating VLM-recognized objects and point-cloud orientation cues,BC,OrienText300K;Objaverse,Open6DOR
Weakly-Supervised 3D,2025,https://arxiv.org/pdf/2312.09625,-,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Leverages CLIP’s 2D–text alignment for weakly supervised 3D semantic transfer,BC ,ReferIt3D;ScanRefer,ReferIt3D;ScanRefer
LLM-3DP,2025,https://arxiv.org/pdf/2501.18733,https://lmm-3dp-release.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Fuses 2D semantic features via back-projection with point-cloud geometry for unified semantic-geometric representation,BC; Predictive Modeling,Self-built Data,RLBench
OccLLaMA,2024,https://arxiv.org/pdf/2409.03272,https://vilonge.github.io/OccLLaMA_Page/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Assigns semantic labels to 3D  voxels for spatial reasoning,predictive Modeling,NuScenes;Occ3D;NuScenes-QA,nuScenes Benchmark
RoboMM,2024,https://arxiv.org/pdf/2412.07215,-,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Incorpo rates multi-view temporal modeling to generate unified 3D  occupancy grids.,BC,OXE;CALVIN,CALVIN;Meta-World;LIBERO
TraceVLA,2024,https://arxiv.org/pdf/2412.10345,https://tracevla.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Extends this to a 4D  perspective by incorporating time,BC ,BridgeData-v2;OXE,SimplerEnv;LIBERO;WidowX-250
ARM4R,2025,https://arxiv.org/pdf/2502.13142,https://arm4r.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Learns space–time coupling by predicting the evolution of 3D point trajectories,BC; Predictive Modeling,Epic-Kitchens100;RLBench,RLBench;Kinova Gen3
SpatialVLA,2025,https://arxiv.org/pdf/2501.15830,spatialvla.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Uses positional encoding and adaptive spatial grids to project 2D semantics into 3D and generate space-action knowledge graphs,BC ,OXE;RH20T;BridgeData V2,SimplerEnv;LIBERO
Evo-0,2025,https://arxiv.org/pdf/2507.00416,https://mint-sjtu.github.io/Evo-0.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Attaches external geometric modules atop a frozen VLM,BC,RLBench,RLBench
AC-DiT,2025,https://arxiv.org/pdf/2507.01961,https://ac-dit.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Leverages diffusion-based conditional modeling to estimate depth reliability without full 3D reconstruction,BC,Self-built Data;RoboTwin;ManiSkill-HAB,ManiSkill-HAB;RoboTwin
BridgeVLA,2025,https://arxiv.org/pdf/2506.07961,https://bridgevla.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Converts point clouds into multiple rendered 2D views,BC,RoboPoint;RLBench;Self-built Data,RLBench;COLOSSEUM;GemBench
OG-VLA,2025,https://arxiv.org/abs/2506.01196,https://og-vla.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,generates orthographic projections to recover 3D pose,RL,ARNOLD;COLOSSEUM,ARNOLD;COLOSSEUM
pi0,2024,https://arxiv.org/html/2410.24164v1,https://www.physicalintelligence.company/blog/pi0,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,-,,Self-built Data;OXE;Bridge v2;DROID,
RoboPoint,2024,https://arxiv.org/pdf/2406.10721,https://robo-point.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Leverages 2D keypoint back-projection to form structured 3D action cues,predictive Modeling,VQA;Self-built Data,RoboRefIt;WHERE2PLACE
VoxPoser,2023,https://arxiv.org/pdf/2307.05973,https://voxposer.github.io/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Leverages LLM-guided code to generate dense voxel-value maps linking linguistic constraints to spatial geometry,predictive Modeling,null,Real-Robot Evaluation
Spatial Traces,2025,https://arxiv.org/pdf/2508.09032,https://ampiromax.github.io/ST-VLA,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,"Fuses tracked keypoints with depth maps, encoding structure and dy namics in a unified 2D input",BC,Bridge,SimplerEnv
A0,2025,https://arxiv.org/pdf/2504.12636,https://a-embodied.github.io/A0/,Multi-Modal Fusion and Physical World Representation     ,From 2D Images to SPatial Temporal Representations,Predicts interaction points and trajectories in 2D and then lifts them into 3D via depth projection,RL,PixMo-One-Point;HOI4D-22k;DROID-3k;Maniskill-5k,HOI4D-22k;DROID-3k;Maniskill-5k;Real-Robot Evaluation
TriVLA,2025,https://arxiv.org/pdf/2507.01424,https://robertwyq.github.io/univla.github.io/,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Augments a video diffusion model to produce  multi-step visual rollouts,BC ,Bridge;CALVIN ABC;MetaWorld,CALVIN ABC;LIBERO;MetaWorld
UP-VLA,2025,https://arxiv.org/pdf/2501.18867,https://github.com/CladernyJorn/UP-VLA,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages key subgoal image prediction to represent the next salient task state,BC,Bridge;Self-built Data,CALVIN
CoT-VLA,2025,https://arxiv.org/abs/2503.22020,https://cot-vla.github.io/,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages key subgoal image prediction to represent the next salient task state,BC,OXE;EPIC-KITCHENS-100;Something-Something V2;Bridge-V2,LIBERO
DreamVLA,2025,https://arxiv.org/pdf/2507.04447,https://zhangwenyao1.github.io/DreamVLA/,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,"Predicting task-critical cues (dynamic regions, depth, and affordance features)",BC ,CALVIN;Self-built Data,CALVIN ABC-D;LIBERO;
V-jepa 2,2025,https://arxiv.org/pdf/2506.09985,https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages latent-space encoding and prediction to model future state evolution,Predictive Modeling,VideoMix22M;Droid,Something-Something v2;ImageNet;
LUMOS,2025,https://arxiv.org/pdf/2503.10370,http://lumos.cs.uni-freiburg.de/,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages multi-step internal rollouts in a learned world model to evaluate action sequences and select an optimal plan,BC,CALVIN;Self-built Data,CALVIN Challenge
FlowVLA,2025,https://arxiv.org/abs/2508.18269,https://irpn-lab.github.io/FlowVLA/,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages a visual chain-of-thought mechanism to forecast future frames and synthesize physically consistent scenes,BC; Predictive Modeling,LIBERO;SimplerEnv;Bridge V2,LIBERO;SimplerEnv-WidowX;AgileX Cobot;Bridge V2
WorldVLA,2025,https://arxiv.org/pdf/2506.21539,https://github.com/alibaba-damo-academy/RynnVLA-002,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages learned world dynamics to model low-level physics and synthesize future physical evolution,BC; Predictive Modeling,LIBERO-90,LIBERO
VLM-in-the-loop,2025,https://arxiv.org/pdf/2502.01828,https://yilin-wu98.github.io/forewarn/,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages internal multi-step rollouts in a world model to evaluate and select action sequences,BC; Predictive Modeling,Self-built Data,Real-Robot Evaluation
MinD,2025,https://arxiv.org/abs/2502.07591,https://github.com/news-vt/DMWM,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages internal multi-step rollouts to evaluate long-horizon outcomes and select optimal actions,RL ,RT-1;RoboMind;OXE;,Franka Research 3
WMPO,2025,https://arxiv.org/pdf/2511.09515,https://wm-po.github.io/,Multi-Modal Fusion and Physical World Representation     ,Dynamic and Predictive World Models,Leverages imagined interaction in a video world model to replace costly physical interaction,RL; Predictive Modeling,OXE;Cobot Mobile ALOHA;,Mimicgen simulation;Real-Robot Evaluation
OE-VLA,2025,https://arxiv.org/pdf/2505.11214,https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation,From Complex Instructions to Robust and Real-Time Execution  ,Parsing Complex Instractions,Leverages a shared visual encoder and text tokenizer to produce strictly interleaved token streams,BC and Predictive Modeling,MGrounding;CALVIN,OE-CALVIN_base
Interleave-VLA,2025,https://arxiv.org/pdf/2505.02152,https://interleave-vla.github.io/Interleave-VLA-Anonymous/,From Complex Instructions to Robust and Real-Time Execution  ,Parsing Complex Instractions,Leverages special tokenizer tags to insert image features seamlessly into text sequences,BC,Open Interleaved X-Embodiment Dataset,VIMA-Bench
TinkAct,2025,"""https://arxiv.org/pdf/2507.16815",https://jasper0314-huang.github.io/thinkact-vla/,From Complex Instructions to Robust and Real-Time Execution  ,Parsing Complex Instractions,infers and verifies the in tended target via scene parsing and feedback,RL and Predictive Modeling,HowTo100M; COIN; CrossTask,Visual Planning for Assistance
DEEPTHINKVLA,2025,https://arxiv.org/pdf/2511.15669,https://github.com/wadeKeith/DeepThinkVLA,From Complex Instructions to Robust and Real-Time Execution  ,Parsing Complex Instractions,Leverages causal chain-of-thought and outcome-driven RL to resolve ambiguity and align subgoals,BC and Predictive Modeling,Embodied CoT,LIBERO
InSpire,2025,https://arxiv.org/pdf/2505.13888,https://koorye.github.io/proj/Inspire/,From Complex Instructions to Robust and Real-Time Execution  ,Parsing Complex Instractions,leverages explicit spatial queries to prompt the policy for target-robot relative location,BC ,LIBERO-90;CALVIN,LIBERO
AskToAct,2025,https://arxiv.org/pdf/2503.01940,https://github.com/emrecanacikgoz/awesome-conversational-agents,From Complex Instructions to Robust and Real-Time Execution  ,Parsing Complex Instractions,leverages explicit spatial queries to auto-fill missing target-robot information,BC,xlam-IC,Taskbench-IC
OneTwoVLA,2025,https://arxiv.org/pdf/2505.11917,https://one-two-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,leverages structured textual reasoning to generate scene descriptions high-level plans and next-step instructions,RL / BC / Predicative modeling,demonstration trajectories provided by human experts,OneTwoVLA(self create)
PI0.5,2025,https://arxiv.org/pdf/2504.16054,https://www.pi.website/blog/pi05,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,embeds hierarchical reason ing within a single inference chain,BC and Predictive Modeling,Diverse Mobile Manipulator;Diverse Multi-Environment non-mobile robot ;Cross-Embodiment laboratory,PI0.5
Hi Robot,2025,https://arxiv.org/pdf/2502.19417,https://www.pi.website/research/hirobot,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,employ a two-layer scheme where a VLM parses  instructions into atomic sub-tasks,BC and Predictive Modeling,teleoperated robot demonstrations,Hi Robot
LoHoVLA,2025,https://arxiv.org/pdf/2506.00411,-,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,leverages structured textual reasoning to generate scene descriptions high-level plans and next-step instructions,BC and Predictive Modeling,LoHoSet,LoHoRavens
CoT-VLA,2025,https://arxiv.org/pdf/2503.22020,https://cot-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,employs pixel-level subgoal images as explicit intermediates,BC,Open X-Embodiment; EPIC-KITCHENS; Something-Something V2,LIBERO
Embodied-SlotSSM,2023,https://www.arxiv.org/pdf/2511.11478,https://libero-mem.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,employs slot-based object-centric representations to create structured visual intermediates ,BC ,LIBERO-Goal,LIBERO-Mem
RT-Affordance,2024,https://arxiv.org/pdf/2411.02704,https://snasiriany.me/rt-affordance,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,plans tasks by breaking manipulation into manageable affordance steps,BC and Predictive Modeling,RT-1 ;MOO,RT-Affordance
CoA-VLA,2025,https://arxiv.org/pdf/2412.20451,https://chain-of-affordance.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,Treats each affordance link as an implicit planning signal,BC and Predictive Modeling,Droid,LIBERO
VLP,2025,https://arxiv.org/pdf/2401.05577,https://github.com/autodriving-heart/CVPR-2024-Papers-Autonomous-Driving,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,builds a fine-grained library for data-efficient reuse of manipulation patterns.,BC and Predictive Modeling,nuScenes,open-loop planning
Agentic Robot,2025,https://arxiv.org/pdf/2505.23450,https://agentic-robot.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,Produces clear step subgoals sequences for verifiable task decomposition,BC and Predictive Modeling,Open-X-Embodiment,LIBERO
RoboBrain,2025,https://arxiv.org/pdf/2502.21257,https://superrobobrain.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,Leverages a hierarchical framework to map abstract instructions to executable atomic actions,BC and Predictive Modeling and RL,LCS-558K; Image-4M; SI-3.2M,RoboVQA; OpenEQA; ShareRobot
DexVLA,2025,https://arxiv.org/pdf/2502.05855,https://github.com/juruobenruo/DexVLA,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,Leverages temporal alignment to automatically annotate semantic sub-steps in long-horizon sequences,BC and Predictive Modeling,DexVLA(self collecting),LIBERO
AgiBot,2025,https://arxiv.org/pdf/2503.06669,https://opendrivelab.com/AgiBot-World/,From Complex Instructions to Robust and Real-Time Execution  ,Hierarchical Planning and Task Decomposition,Leverages explicit skills during data collection to learn latent action tokens that compress high-dimensional control,BC and Predictive Modeling,AgiBot World;OXE,AgiBot
Yell At Your Robot,2024,https://arxiv.org/pdf/2403.12910,https://yay-robot.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Error Detection and Autonomous Recovery,Leverages  real-time language feedback for instant behavioral correction,BC and Predictive Modeling and RL,Yell At Your Robot,Yell At Your Robot
CLIP-RT,2024,https://arxiv.org/pdf/2411.00508,https://clip-rt.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Error Detection and Autonomous Recovery,Leverages language feedback as an action template via similarity matching for retrain-free correction,,Open X-Embodiment (OXE); self collecting,LIBERO
OneTwoVLA,2025,https://arxiv.org/pdf/2505.11917,https://one-two-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Error Detection and Autonomous Recovery,Actively queries humans to resolve uncertainty before acting,,OneTwoVLA,OneTwoVLA
CorrectNav,2025,https://arxiv.org/pdf/2508.10416,https://correctnav.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Error Detection and Autonomous Recovery,Leverages iterative self-correction by using the model's own error trajectories to generate corrective actions and data,BC and Predictive Modeling and RL,VLN-CE; VLN-CE R2R; LLaVA-Video,VLN-CE;R2R-CE;Val-Unseen
FPC-VLA,2025,https://arxiv.org/pdf/2509.04018,https://fpcvla.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Error Detection and Autonomous Recovery,Leverages a VLM to assess action semantics and generate corrective language feedback,BC and Predictive Modeling and RL,OXE;BridgeV2;Google Fractal,SIMPLER
Agentic Robot,2025,https://arxiv.org/pdf/2505.23450,https://agentic-robot.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Error Detection and Autonomous Recovery,Achieves autonomous correction via a plan-act-verify loop with VLM-based validation and recovery,BC,Open-X-Embodiment; LIBERO,LIBERO-Spatial;LIBERO-Object;LIBERO-Goal
BitVLA,2025,https://arxiv.org/pdf/2506.07530,https://github.com/ustcwhy/BitVLA,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,achieves ultra-low-precision efficiency  via ternary 1-bit compression and distillation,BC,LLaVA 1.5-558k;MammoTH-VL,VQA
Evo-1,2025,https://arxiv.org/pdf/2511.04555,https://github.com/MINT-SJTU/Evo-1,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Provides a lightweight 77M-parameter design,BC,Meta-World; RoboTwin,Meta-World
SQAP-VLA,2025,https://arxiv.org/pdf/2509.09090,https://github.com/ecdine/SQAP-VLA,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Introduces perceptual pruning strategies on the basis of quantization,BC and Predictive Modeling,Open X-Embodiment,standard robotics simulation benchmark
TinyVLA,2025,https://arxiv.org/pdf/2409.12514,https://tiny-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Adopt lightweight backbones directly,BC ,LLaVA,MetaWorld
VLA-Adapter,2025,https://arxiv.org/pdf/2509.09372,https://vla-adapter.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages lightweight adapters to graft large-model knowledge into smaller policies,BC and Predictive Modeling,Open X-Embodiment; DROID,LIBERO
NORA,2025,https://arxiv.org/pdf/2504.19854,https://declare-lab.github.io/nora,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Adopt lightweight backbones directly ,BC and Predictive Modeling,Open X-Embodiment,Real-world WidowX-250
RoboMamba,2024,https://arxiv.org/pdf/2406.04339,https://sites.google.com/view/robomamba-web,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages a Mamba backbone for linear-time scaling and faster inference,BC,LLaVA-LCS 558K;LLaVA 1.5 655K; ShareGPT4V-SFT,VQAv2;OKVQA;GQA
MoLe-VLA,2025,https://arxiv.org/pdf/2503.20384,https://sites.google.com/view/mole-vla,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,leverages layer skipping to reduce FLOPs ,BC and Predictive Modeling,RLBench,RLBench
CEED-VLA,2025,https://arxiv.org/pdf/2506.13725,https://irpn-eai.github.io/CEED-VLA/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Design early exit mechanisms.,BC ,CALVIN; LIBERO,CALVIN ABC
DeeR-VLA,2024,https://arxiv.org/pdf/2411.02359,https://github.com/yueyang130/DeeR-VLA,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Design early exit mechanisms. ,BC and Predictive Modeling,CALVIN; LAION-2B,CALVIN
VLA-Cache,2025,https://arxiv.org/pdf/2502.02175,https://vla-cache.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Uuses adaptive caching that differentiates static and dynamic tokens,BC and Predictive Modeling and RL,CLVR_Jaco_Play,LIBERO
SpecPrune-VLA,2025,https://arxiv.org/pdf/2509.05614,https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,performs action aware pruning conditioned on history and current observations,BC and Predictive Modeling,-,LIBERO
CogVLA,2025,https://arxiv.org/pdf/2508.21046,https://jiutian-vl.github.io/CogVLA-page/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,reduces computation through  instruction-driven visual token sparsification.,Predictive Modeling,LIBERO; self collecting,LIBERO
AcceleratingVLA,2025,https://arxiv.org/pdf/2503.02310,https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages parallel decoding to generate full action chunks in one pass,BC and Predictive Modeling,CALVIN,CALVIN
OpenVLA-OFT,2025,https://arxiv.org/pdf/2502.19645,https://github.com/moojink/openvla-oft,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages parallel decoding to generate full action chunks in one pass,Predictive Modeling,ALOHA,LIBERO
Spec-VLA,2025,https://arxiv.org/pdf/2507.22424,https://github.com/PineTreeWss/SpecVLA,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages speculative decoding to emit candidate action tokens in one pass,BC,generating by OpenVLA,LIBERO
FAST,2025,https://arxiv.org/pdf/2501.09747,https://www.pi.website/research/fast,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Compresses action sequences ,BC and Predictive Modeling and RL,DROID; BRIDGE v2; Open X-Embodiment,DROID
VQ-VLA,2025,https://arxiv.org/pdf/2507.01016,https://xiaoxiao0406.github.io/vqvla.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages a VQ-VAE tokenizer to compress long trajectories into compact discrete tokens,BC,Open X-Embodiment;LIBERO;ManiSkill;RLBench,LIBERO-10;LIBERO-GOAL;LIBERO-90
XR-1,2025,https://arxiv.org/pdf/2511.02776,https://xr-1-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages VQ-VAE–learned discrete visual–motor tokens to guide policy learning,BC ,OXE;RoboMIND;Ego4D;XR-D,XR-1
SmolVLA,2025,https://arxiv.org/pdf/2506.01844,https://github.com/huggingface/smollm,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages asynchronous execution to predict the next action chunk during current execution,BC ,Hugging Face ; LIBERO; Meta-World,LIBERO
Time-Diffusion Policy,2025,https://arxiv.org/pdf/2506.09422,https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages a unified velocity field to replace time-varying denoising,BC ,RLBench,RLBench
Discrete Diffusion VLA,2025,https://arxiv.org/pdf/2508.20072,https://github.com/Liang-ZX/DiscreteDiffusionVLA,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Discretizes actions into tokens and employs masked diffusion with parallel prediction,BC ,OXE;Fractal;BridgeData-V2;LIBERO,SimplerEnv-Fractal
ECoT-Lite,2025,https://arxiv.org/pdf/2505.08243v1,https://github.com/MichalZawalski/embodied-CoT,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages reasoning traces during training while bypassing explicit reasoning at inference,BC,LIBERO and Bridge V2,LIBERO
V-JEPA,2025,https://arxiv.org/pdf/2506.09985,https://github.com/facebookresearch/vjepa2,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Predicting compressed semantic representations instead of raw pixels,Predictive Modeling,VideoMix22M; Droid,Kinetics-400;Something-Something V2
Fast-in-Slow,2025,https://arxiv.org/pdf/2506.01953,https://fast-in-slow.github.io/,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages a dual-system model coordinating slow reasoning and fast reactions,BC and Predictive Modeling,Open X-Embodiment;DROID;RoboMIND,RLBench
AMS,2025,https://arxiv.org/pdf/2405.09045,https://github.com/AMS-Net/ams-net.github.io,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Introduces OS-level action context caching and replay mechanisms,BC ,AMSNet,MLLM4EDA
FedVLA,2025,https://arxiv.org/pdf/2508.02190,-,From Complex Instructions to Robust and Real-Time Execution  ,Real-Time Execution and Computing Efficiency,Leverages federated learning for efficient distributed VLA training,BC,Open-X Embodiment,Meta-World
Octo,2024,https://arxiv.org/pdf/2405.12213,https://octo-models.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Pretrain Transformer on 800k trajectories and use lightweight adapters,BC and Predictive Modeling,OXE,WidowX
DexVLA,2025,https://arxiv.org/pdf/2502.05855,https://dex-vla.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Pretrain diffusion action experts across morphologies with a three stage curriculum,BC ,self collecting,LIBERO
RoboCat,2023,https://arxiv.org/pdf/2306.11706,https://github.com/kyegomez/RoboCAT,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain on heterogeneous multi robot data and update on real trajectories,BC ,ImageNet;DeepMind Control Suite,RGB Stacking Benchmark
Dita,2024,https://arxiv.org/pdf/2503.19757,https://robodita.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Use OXE dataset and diffusion Transformers to learn cross environment behaviors,BC ,Open X-Embodiment (OXE) datasets; Droid,SimplerEnv
EO-1,2025,https://arxiv.org/pdf/2508.21112,https://github.com/eo-robotics/EO1,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Pretrain a shared backbone on 1.5M EO Data,BC,LLaVA-1.5;LLaVA-Video-178K;PixMo-Points,RoboVQA
R3M,2022,https://arxiv.org/pdf/2203.12601,https://sites.google.com/view/robot-r3m/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain visual encoders on massive human first-person videos,Predictive Modeling,Ego4D,Franka Kitchen
Ego4D,2022,https://arxiv.org/pdf/2110.07058,https://ego4d-data.org/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain visual encoders on massive human first-person videos,Predictive Modeling,Ego4D,Episodic Memory
GR-1,2023,https://arxiv.org/pdf/2312.13139,https://gr1-manipulation.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain on massive human egocentric video datasets,Predictive Modeling,Ego4D,CALVIN
Gr-2,2024,https://arxiv.org/pdf/2410.06158,https://gr2-manipulation.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain on massive human egocentric video datasets,Predictive Modeling,HowTo100M; Ego4D; Something-Something V2 (SSV2),End-to-End Bin Picking
ICIL,2024,https://arxiv.org/pdf/2408.15980,https://icrt.dev/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages in-context learning to infer tasks from few-shot demonstrations without retraining,BC and Predictive Modeling,DROID,ICIL
TRA,2025,https://arxiv.org/pdf/2502.05454,https://tra-paper.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Use temporal contrastive loss to structure representation space,BC and Predictive Modeling and RL,BridgeDataV2,Real-world tabletop manipulation tasks
ObjectVLA,2025,"""https://arxiv.org/pdf/2502.19250",https://objectvla.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Jointly train on robot trajectories and box labeled VL corpora,BC ,ObjectVLA-Demo,ObjectVLA-Bench
LERF,2023,https://arxiv.org/pdf/2303.09553,https://www.lerf.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Fuse CLIP with 3D NeRFs,BC,LERF-Demo,LERF-Bench
RUM,2025,https://arxiv.org/pdf/2508.12922,https://github.com/kairanzhao/RUM,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pair large scale home demonstrations with multimodal LLM reasoning,BC and Predictive Modeling,-,-
Align-Then-Steer,2025,https://arxiv.org/pdf/2509.02055,https://github.com/TeleHuman/Align-Then-Steer,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages a latent-space adapter to steer a frozen VLA model non-invasively,BC and Predictive Modeling,DROID; Kuka; ALOHA,RoboTwin 1.0
CACTI,2022,https://arxiv.org/pdf/2212.05711,https://cacti-framework.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages Stable Diffusion for zero-shot inpainting to diversify expert images without extra rollouts,BC and Predictive Modeling,CACTI-Sim-100,CACTI-Sim-100
GenAug,2023,https://arxiv.org/pdf/2302.06671,https://genaug.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages text-to-image synthesis from few-shot demos and prompts to generate diverse consistent scenes,BC ,Self-built Data,-
ROSIE,2023,https://arxiv.org/pdf/2302.11550,https://diffusion-rosie.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Distill internet scale VLM knowledge into robot training,BC and Predictive Modeling,RT-1; self collecting,ROSIE
LMM-3DP,2025,https://arxiv.org/pdf/2501.18733,https://lmm-3dp-release.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages a high-level planner for abstract knowledge and a low-level executor for reusable skills,BC,Self-built Data,Real-Robot Evaluation
BAKU,2024,https://arxiv.org/pdf/2406.07539,https://baku-robot.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages dynamic multimodal sensor fusion,BC ,LIBERO-90; Meta-World; DeepMind Control Suite/DM Control,LIBERO-90;Meta-World
StructDiffusion,2022,https://arxiv.org/pdf/2211.04604,https://structdiffusion.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages language guided diffusion to generate multiple action structures,Predictive Modeling,-,Google Scanned Objects with Pybullet
Think Small Act Big,,https://arxiv.org/pdf/2504.00420,-,Generalization and Adaptation for Continuous Learning,Continua Learning and Incremental Skill Acquisition,Leverages new prompts or codebook entries to add skills without modifying existing components,BC,MimicGen,LIBERO
SPECI,,https://arxiv.org/pdf/2504.15561,-,Generalization and Adaptation for Continuous Learning,Continua Learning and Incremental Skill Acquisition,Leverages new prompts or codebook entries to add skills without modifying existing components,BC,LIBERO,LIBERO
InstructVLA,2025,https://arxiv.org/pdf/2507.17520,https://yangs03.github.io/InstructVLA_Home/,Generalization and Adaptation for Continuous Learning,Continua Learning and Incremental Skill Acquisition,Leverages a two-stage paradigm with a MoE to route between reasoning and action modules,BC and Predictive Modeling,Bridge Dataset;Fractal Dataset;RT-1/RT-1-X,VLMEvalKit
iManip,2025,https://arxiv.org/pdf/2503.07087,https://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models,Generalization and Adaptation for Continuous Learning,Continua Learning and Incremental Skill Acquisition,Add skill specific weights while freezing old ones,BC ,RLBench,RLBench
ExpReSVLA,2025,https://arxiv.org/pdf/2511.06202,-,Generalization and Adaptation for Continuous Learning,Continua Learning and Incremental Skill Acquisition,Use Compressed Experience Replay,BC,OpenVLA pretraining dataset,LIBERO
SLIM,2025,https://arxiv.org/pdf/2410.09615,https://github.com/Paramathic/slim,Generalization and Adaptation for Continuous Learning,sim-to-real Gap in Deployment,Compress RGB into segmentation and depth maps,BC and Predictive Modeling,C4,MMLU;PIQA
MaiSkill3,2024,https://arxiv.org/pdf/2410.00425,https://github.com/haosulab/ManiSkill,Generalization and Adaptation for Continuous Learning,sim-to-real Gap in Deployment,Leverages GPU-parallel rendering domain randomization and background composition,BC,ManiSkill3,ManiSkill3
GenAug,2023,https://arxiv.org/abs/2302.06671,https://github.com/genaug/genaug,Generalization and Adaptation for Continuous Learning,sim-to-real Gap in Deployment,Leverages  web scale image generative models to synthesize images from few demonstrations,,10 real world table,real world evaluation
DreamGen,2025,https://arxiv.org/pdf/2505.12705,https://github.com/nvidia/GR00T-dreams,Generalization and Adaptation for Continuous Learning,sim-to-real Gap in Deployment,Train a world model on massive real world data,Predictive Modeling and RL,GR1 humanoid teleoperation pick-and-place; RoboCasa (simulation); DROID,RoboCasa
RynnVLA-001,2025,https://arxiv.org/pdf/2509.15212,https://github.com/alibaba-damo-academy/RynnVLA-001,Generalization and Adaptation for Continuous Learning,sim-to-real Gap in Deployment,Pretrain large scale video generation with human centric trajectory modeling,BC and Predictive Modeling,self collecting ego-centric human manipu-demo; EgoDex,Calvin
RIDG,2024,https://arxiv.org/pdf/2412.09858,https://generalist-distillation.github.io/,Generalization and Adaptation for Continuous Learning,Online Interatction and Reinforcement Learning,Train specialist RL policies then distill trajectories into VLA,RL ,generating by RL,Connector Insertion
Refined Policy Distillation,2025,https://arxiv.org/pdf/2503.05833,https://refined-policy-distillation.github.io/,Generalization and Adaptation for Continuous Learning,online Interatction and Reinforcement Learning,Add MSE constraint to guide RL agent,RL ,ManiSkill3,ManiSkill3
iRe-VLA,2025,https://arxiv.org/pdf/2501.16664,https://github.com/HaochenZ11/IRef-VLA,Generalization and Adaptation for Continuous Learning,online Interatction and Reinforcement Learning,Freeze backbone and train lightweight action head in alternating phases,RL ,Metaworld,MetaWorld
