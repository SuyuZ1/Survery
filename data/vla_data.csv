略称,Year,Paper URL,Website URL,Challenge Tag,Sub-Challeng Tag,How to Solve,Training Type,Dataset,Evaluation
VLA-Example,2024,https://example.com/paper.pdf,https://example.com,Multi-Modal Fusion and Physical World Representation; From Complex Instructions to Robust and Real-Time Execution; Generalization and Adaptation for Continuous Learning; Security Interpretability and Reliable Interaction;Dataset Construction and Benchmarking Standards,sub-challeng-1;sub-challeng-2, Methods,BC,Example Dataset1;Example Dataset2,Example Bechmark1;Example Bechmark2
OTTER,2021,https://arxiv.org/pdf/2503.03734,https://ottervla.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Sematics Perception and Physical Interation,introdues a text-aware feature extraction which preserves semantics aligned with task description,BC,MIMIC-IT,POPE;MSRVTT-QA
LIV,2023,https://proceedings.mlr.press/v202/ma23b/ma23b.pdf,,Multi-Modal Fusion and Physical World Representation ,The GAP between Sematics Perception and Physical Interation,introdues a contrastive framework on robot-control data to construct a joint vision–language embeddingspace,RL,Hopper-v2; HalfCheetah-v2; Walker2d-v2,MuJoCo
CoT-VLA,2025,https://www.alphaxiv.org/pdf/2407.03982,https://cot-vla.github.io/,From Complex Instructions to Robust Real-Time Execution Hierarchical Planning and Task Decomposition, Employs pixel-level subgoal images as explicit intermediates,BC, CalVIN ;RLBench, RLBench
