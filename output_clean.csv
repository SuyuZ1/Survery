CO-RFT,2025,https://arxiv.org/pdf/2508.02219,https://github.com/cccedric/conrft,3,online Interatction and Reinforcement Learning, designs a chunked temporal difference learning mechanism that feeds entire action sequences into the critic to predict multi step returns ,RL ,CO-RFT,CO-RFT
VLM-RMs,2023,https://arxiv.org/pdf/2310.12921,https://github.com/AlignmentResearch/vlmrm,3,online Interatction and Reinforcement Learning,Infer rewards via perceptual alignment in shared embedding space,RL and Predictive Modeling,-,CartPole;MountainCar
RoboCLIP,2023,https://arxiv.org/pdf/2310.07899,https://sites.google.com/view/roboclip/home,3,online Interatction and Reinforcement Learning,Leverages video trajectories by computing video language similarity for sparse rewards ,BC and Predictive Modeling,HowTo100M,MetaWorld;Franka Kitchen
Affordance-Guided RL,2024,https://arxiv.org/pdf/2407.10341,https://sites.google.com/view/affordance-guided-rl,3,online Interatction and Reinforcement Learning,Convert VLM predicted grasp points and trajectories into dense rewards,BC and Predictive Modeling,Bridge Data,PyBullet Bin-Sorting Cloth Covering
RL VLM-F,2024,https://arxiv.org/pdf/2402.03681,https://rlvlmf2024.github.io/,3,online Interatction and Reinforcement Learning,Leverages GPT-4V to infer preference-based rewards from observation pairs without human labels,BC ,-,OpenAI Gym CartPole
GRAPE,2024,https://arxiv.org/pdf/2411.19309,https://grape-vla.github.io/,3,online Interatction and Reinforcement Learning,Leverages VLMs to decompose tasks and generate stage-wise preferences for multi-objective rewards,RL and Predictive Modeling,Real-world SFT dataset; Simpler-Env SFT;  LIBERO,Real-world 30 tasks
Eureka,2023,https://arxiv.org/pdf/2310.12931,https://eureka-research.github.io/,3,online Interatction and Reinforcement Learning, Prompt LLM with environment code and task specs to generate rewards,RL ,-,Isaac Gym
VIP,,https://arxiv.org/pdf/2210.00030,https://sites.google.com/view/vip-rl,3,online Interatction and Reinforcement Learning,Perform implicit value optimization from video,,Ego4D,FrankaKitchen
VLA-RL,2025,https://arxiv.org/pdf/2505.18719,https://github.com/GuanxingLu/vlarl,3,online Interatction and Reinforcement Learning,Finetune VLM into a structured process reward model,RL and Predictive Modeling,OpenVLA-7B; LIBERO,LIBERO
AutoRT,2025,https://arxiv.org/pdf/2401.12963,https://auto-rt.github.io/,4,Reliability and Safety Assurance,Leverages structured prompting to encode multi level constraints,BC,AutoRT,AutoRT
SafeVLA,2025,https://arxiv.org/pdf/2503.03480,https://pku-safevla.github.io/,4,Reliability and Safety Assurance,Leverages a cost function in a constrained MDP to model physically hazardous behaviors,RL ,CHORES,Safety-CHORES
Genimi Robotics,2025,https://arxiv.org/pdf/2503.20020,https://github.com/google-deepmind/gemini-robotics-sdk,4,Reliability and Safety Assurance,Leverages Constitutional AI post-training on safety data to enforce human-centric principles,RL / BC / Predicative modeling,ALOHA 2;Embodied Reasoning;VQA,ERQA
GPI,2025,https://arxiv.org/pdf/2508.11960,-,4,Reliability and Safety Assurance,Leverages confidence estimation probabilistic action generation and language guided backtracking to replan under uncertainty,RL and Predictive Modeling,-,VIMA-Bench;Ravens
RationalVLA,2025,https://arxiv.org/pdf/2506.10826,https://irpn-eai.github.io/RationalVLA/,4,Reliability and Safety Assurance,Uses a learnable refusal token to reject unsafe or invalid commands,BC and Predictive Modeling and RL,CALVIN A/B/C splits + RAMA,CALVIN ABC
Diffusion-VLA,2024,https://arxiv.org/pdf/2412.03293,https://diffusion-vla.github.io/,4,Interpretability and Trustworthy Interaction,Condition diffusion policy on natural language reasoning,Predictive Modeling and RL,Droid;OXE,eal-World Multi-Task Learning
ECoT,2024,https://arxiv.org/pdf/2407.08693,https://embodied-cot.github.io/,4,Interpretability and Trustworthy Interaction, Leverages editable step-by-step rationales that users can correct via language,BC,Bridge Data;RT-2-X,ECoT
CoT-VLA,2025,https://arxiv.org/pdf/2503.22020,https://cot-vla.github.io/,4,Interpretability and Trustworthy Interaction,Adds visual subgoal images to render intermediate plans observable,BC and Predictive Modeling,Jaco Play;Berkeley Autolab UR5;Berkeley Fanuc Manipulation,LIBERO
RT-H,2024,https://arxiv.org/pdf/2403.01823,https://rt-hierarchy.github.io/,4,Interpretability and Trustworthy Interaction,Leverages separated language–action generation to enable self-explanation and language-level intervention,BC,Kitchen,RT-H
CrayonRobo,2025,https://arxiv.org/pdf/2505.02166,-,4,Interpretability and Trustworthy Interaction,Uses structured semantically explicit visual prompts to externalize decision logic into a shared and interpretable language,BC,SAPIEN + PartNet-Mobility,CrayonRobo
SwitchVLA,2025,https://arxiv.org/pdf/2506.03574,https://switchvla.github.io/,4,Interpretability and Trustworthy Interaction,Use structured task switching with rollback of conflicting actions,BC and Predictive Modeling,LIBERO-Goal,LIBERO-Goal
Hi Robot,2025,https://arxiv.org/pdf/2502.19417,https://www.pi.website/research/hirobot,4,Interpretability and Trustworthy Interaction,Outputs readable low-level commands from a high-level planner ,BC,teleoperated robot demonstrations;D_syn,Hi Robot
GraSPVLA,2025,https://arxiv.org/pdf/2511.04357,https://github.com/PKU-EPIC/GraspVLA,4,Interpretability and Trustworthy Interaction,Uses symbolic state conversion of visual inputs for planning in a symbolic space,BC and Predictive Modeling,Bridge Data; RT-X,DAHLIA
DIARC-OpenVLA,2025,https://arxiv.org/pdf/2502.04558v1,-,4,Interpretability and Trustworthy Interaction,Train linear probes to map hidden activations to symbolic states for transparent monitoring,BC and Predictive Modeling and RL,Dataset of openvla,LIBERO-spatial
Moto,2025,https://arxiv.org/pdf/2401.03306,https://github.com/linhlpv/awesome-offline-to-online-RL-papers,5,Multi-Source Heterogeneous Data,Uses unsupervised or self-supervised learning to acquire task-centric latent action representations from videos,,MetaWorld; Franka Kitchen,MetaWorld
LAPA,2024,https://arxiv.org/pdf/2410.11758,https://latentactionpretraining.github.io/,5,Multi-Source Heterogeneous Data,Uses unsupervised or self-supervised learning to acquire task-centric latent action representations from videos,BC and RL,Language Table; OXE;Something-Something V2,WidowX 7DOF
UniVLA,2025,https://arxiv.org/pdf/2505.06111,https://github.com/OpenDriveLab/UniVLA,5,Multi-Source Heterogeneous Data,Uses unsupervised or self-supervised learning to acquire task-centric latent action representations from videos,BC,OXE; Ego4D; Bridge Data,CALVIN
RDT-1B,2024,https://arxiv.org/pdf/2410.07864,https://rdt-robotics.github.io/rdt-robotics/,5,Multi-Source Heterogeneous Data,Map diverse robot actions into unified physical or latent semantic vectors,BC,RT-1;DROID;RH20T,RDT-1B
AgiBot,2025,https://arxiv.org/pdf/2503.06669,https://opendrivelab.com/AgiBot-World/,5,Multi-Source Heterogeneous Data,Map diverse robot actions into unified physical or latent semantic vectors,BC and Predictive Modeling,AgiBot Dataset;OXE,AgiBot
Cross-Embodied Learning,2024,https://arxiv.org/pdf/2408.11812,https://crossformer-model.github.io/,5,Multi-Source Heterogeneous Data,Tokenize visual and proprioceptive inputs for a shared Transformer,BC and RL,DROID;ALOHA-multi-task;GNM,WidowX Manipulation
RT-1,2022,https://arxiv.org/pdf/2212.06817,https://robotics-transformer1.github.io/,5,Multi-Source Heterogeneous Data,Use unified tokenization semantic alignment or self supervised learning for VLA grounding,BC ,RT-1,RT-1
ViSA-Flow,2025,https://arxiv.org/pdf/2505.01288,https://visaflow-web.github.io/ViSAFLOW/,5,Multi-Source Heterogeneous Data,Use unified tokenization semantic alignment or self supervised learning for VLA grounding,BC and Predictive Modeling,AMASS; HumanML3D; Motion-X,CALVIN ABC
Humanoid-VLA,2025,https://arxiv.org/pdf/2502.14795,https://github.com/AllenXuuu/HumanVLA,5,Multi-Source Heterogeneous Data,Use unified tokenization semantic alignment or self supervised learning for VLA grounding,BC and RL,Bridge Data; RT-X,T2M
EgoVLA,2025,https://arxiv.org/pdf/2507.12440,https://rchalyang.github.io/EgoVLA/,5,Multi-Source Heterogeneous Data,Use MANO hand models and inverse kinematics,BC and Predictive Modeling,Ego-Centric Human Manipulation Dataset,Ego Humanoid Manipulation Benchmark
Dexwild,2025,https://arxiv.org/pdf/2505.07813,https://dexwild.github.io/,5,Multi-Source Heterogeneous Data,Use MANO hand models and inverse kinematics,BC and Predictive Modeling,DexWild-System human demo ,Dexwild
CACTI,2022,https://arxiv.org/pdf/2212.05711,https://cacti-framework.github.io/,5,Multi-Source Heterogeneous Data,augment robot data via inpainting or restyling,BC,CACTI,CACTI
GenAug,2023,https://arxiv.org/pdf/2302.06671,https://genaug.github.io/,5,Multi-Source Heterogeneous Data,augment robot data via inpainting or restyling,BC and Predictive Modeling,GenAug,GenAug
ROSIE,2023,https://arxiv.org/pdf/2302.11550,https://diffusion-rosie.github.io/,5,Multi-Source Heterogeneous Data,provides semantic-level enrichment using VLM priors,BC and Predictive Modeling,RT-1,ROSIE
Re-Mix,2024,https://arxiv.org/pdf/2408.14037,https://github.com/jhejna/remix,5,Multi-Source Heterogeneous Data,Adjust sampling weights of heterogeneous data subsets via performance feedback,BC,Bridge Data;OXE; RoboMimic NutAssemblySquare,RoboMimic NutAssemblySquare
RH20T,2023,https://arxiv.org/pdf/2307.00595,https://rh20t.github.io/,5,Multi-Source Heterogeneous Data,Enforce strict temporal alignment across sensors,BC and Predictive Modeling,RH20T,RH20T
BridgeData v2,2023,https://arxiv.org/pdf/2308.12952,https://rail-berkeley.github.io/bridgedata/,5,Multi-Source Heterogeneous Data,integrates diverse data types into a standardized format,BC and Predictive Modeling,Bridge Data,Bridge Data
RoboCasa,2024,https://arxiv.org/pdf/2406.02523,https://robocasa.ai/,5,Multi-Source Heterogeneous Data,Provide large scale high fidelity digital environments,BC and Predictive Modeling and RL,RoboCasa,RoboCasa
CoVLA,2025,https://arxiv.org/pdf/2408.10845,https://turingmotors.github.io/covla-ad/,5,Multi-Source Heterogeneous Data,Provide large scale high fidelity digital environments,BC and Predictive Modeling and RL,CoVLA,CoVLA
Ego4D,2022,https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf,https://ego4d-data.org/,5,Multi-Source Heterogeneous Data,teaching robots to operate in human environments,BC and Predictive Modeling and RL,Ego4D,Ego4D
EPIC-KITCHENS,2020,https://arxiv.org/pdf/2005.00343,https://epic-kitchens.github.io/2025,5,Multi-Source Heterogeneous Data,teaching robots to operate in human environments,BC and Predictive Modeling,EPIC-KITCHENS,EPIC-KITCHENS
Ego-Exo4D,2024,https://arxiv.org/pdf/2311.18259,https://ego-exo4d-data.org/,5,Multi-Source Heterogeneous Data,Fuse first person and third person perspectives,BC and Predictive Modeling and RL,Ego-Exo4D,Ego-Exo4D
RoboMM,2024,https://arxiv.org/pdf/2412.07215,https://github.com/EmbodiedAI-RoboTron/RoboTron-Mani,5,Multi-Source Heterogeneous Data,Use three level semantic alignment for joint training,BC and Predictive Modeling,RoboData,CALVIN;Meta-World
OXE,2023,https://arxiv.org/pdf/2310.08864,https://robotics-transformer-x.github.io/,5,Multi-Source Heterogeneous Data,Aggregate multiple datasets into a single benchmark,BC and Predictive Modeling,OXE,OXE
RLBench,2025,https://arxiv.org/pdf/1909.12271,https://github.com/stepjam/RLBench,5,Evaluation and Benchmark,-,BC and Predictive Modeling and RL,RLBench,RLBench
RoboMimic,2021,https://arxiv.org/pdf/2108.03298,https://github.com/ARISE-Initiative/robomimic,5,Evaluation and Benchmark,Uses human demonstration data to evaluate offline learning methods and identify challenges in leveraging human-generated data,-,Machine-Generated (MG);Proficient-Human (PH);Multi-Human (MH),RoboMimic
EUQ,2025,https://arxiv.org/pdf/2502.13105v2,-,5,Evaluation and Benchmark,Uses a human-assessed multidimensional scoring system to capture process quality beyond binary success,-,-,-
ManiSkills,2024,https://arxiv.org/pdf/2410.00425,https://github.com/haosulab/ManiSkill,5,Evaluation and Benchmark,Contributes standardized APIs and task suites,BC and Predictive Modeling and RL,ManiSkill3,ManiSkill3
robosuits,2020,https://arxiv.org/pdf/2009.12293,https://github.com/ARISE-Initiative/robosuite,5,Evaluation and Benchmark,Contributes standardized APIs and task suites,BC and Predictive Modeling and RL,-,RoboSuite
CALVIN,2022,https://arxiv.org/pdf/2112.03227,https://github.com/mees/calvin,5,Evaluation and Benchmark,require the execution of long sequences of language-guided operations,BC and Predictive Modeling and RL,CALVIN,CALVIN
LIBERO,2023,https://arxiv.org/pdf/2306.03310,https://libero-project.github.io/intro.html,5,Evaluation and Benchmark,Introduces the first lifelong-robotics benchmark with standardized metrics,BC and Predictive Modeling and RL,LIBERO,LIBERO
Ego-Exo4D,2024,https://arxiv.org/pdf/2311.18259,https://ego-exo4d-data.org/,5,Evaluation and Benchmark,Introdues synchronized first-third-person recordings,BC and Predictive Modeling and RL,Ego-Exo4D,Ego-Exo4D
From Intention to Execution,2025,https://arxiv.org/pdf/2506.09930,https://ai4ce.github.io/INT-ACT/,5,Evaluation and Benchmark,Uses intention-execution gap probing to cover object diversity linguistic complexity and visual-language reasoning,BC and Predictive Modeling and RL,Bridge Data,INT-ACT
InstructVLA,2025,https://arxiv.org/pdf/2507.17520,https://yangs03.github.io/InstructVLA_Home/,5,Evaluation and Benchmark,Releases SimplerEnv-Instruct with 80 zero-shot tasks,BC and Predictive Modeling,Bridge Data;OXE;RT-1;RT-2,SimplerEnv;SimplerEnv-Instruct
Benchmarking VLAs,2024,https://arxiv.org/pdf/2411.05821,https://multinet.ai/static/pages/Multinetv01.html,5,Evaluation and Benchmark,Uses unified IO metrics and multi robot coverage as a blueprint shifting focus from tasks to metrics,BC,OXE,OXE
